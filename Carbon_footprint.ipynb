{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pygad\n",
        "!pip install streamlit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import xgboost as xgb\n",
        "import pygad\n",
        "import streamlit as st\n",
        "\n",
        "# Load Dataset\n",
        "dataset_path = 'expanded_carbon_dataset.csv'  # Replace with your actual dataset path\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Preprocessing: Handling missing values, normalization\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Convert columns to numeric if possible before filling NaN\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':  # Check if the column is of object type\n",
        "        try:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, invalid parsing will be set as NaN\n",
        "        except:\n",
        "            pass  # Skip if column cannot be converted\n",
        "\n",
        "df.fillna(df.mean(), inplace=True)  # Now fill NaN after attempting conversion\n",
        "\n",
        "scaled_features = scaler.fit_transform(df.drop(columns=['id', 'timestamp', 'user_type', 'country', 'sector', 'diet_impact']))\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_features, df['emissions_tons'], test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# LSTM Model for Time-Series Data\n",
        "lstm_model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(loss='mse', optimizer='adam')\n",
        "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# ANN Model for Non-Linear Data\n",
        "ann_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "ann_model.compile(loss='mse', optimizer='adam')\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# XGBoost Model for Enhanced Predictions\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# PyGAD Optimization to Suggest Reduction Strategies\n",
        "def fitness_function(ga_instance, solution, solution_idx):\n",
        "    \"\"\"\n",
        "    Calculates the fitness of a solution.\n",
        "\n",
        "    Args:\n",
        "        ga_instance: The instance of the pygad.GA class.\n",
        "        solution: The solution to evaluate.\n",
        "        solution_idx: The index of the solution within the population.\n",
        "\n",
        "         Returns:\n",
        "        The fitness value of the solution (negative prediction to minimize emissions).\n",
        "    \"\"\"\n",
        "    prediction = xgb_model.predict([solution])[0]\n",
        "    return -prediction  # Minimizing emissions\n",
        "\n",
        "\n",
        "ga_instance = pygad.GA(num_generations=10, num_parents_mating=5, fitness_func=fitness_function,\n",
        "                        sol_per_pop=10, num_genes=X_train.shape[1])\n",
        "ga_instance.run()\n",
        "\n",
        "# Final Model Evaluation\n",
        "final_prediction = xgb_model.predict(X_test)\n",
        "mse = np.mean((final_prediction - y_test) ** 2)\n",
        "print(f\"Final Model MSE: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXuc0QnADJsP",
        "outputId": "654d6c17-2f17-4bc3-97d9-f9bad6ea7f9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygad in /usr/local/lib/python3.11/dist-packages (3.4.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pygad) (3.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pygad) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pygad) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygad) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.17.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.42.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.27.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 1469.0291 - val_loss: 830.9280\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 832.6765 - val_loss: 830.8151\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 825.4932 - val_loss: 71.2400\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 36.5412 - val_loss: 3.4308\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 10.6980 - val_loss: 1.7979\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - loss: 7.7518 - val_loss: 1.4021\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 6.0187 - val_loss: 0.9178\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 5.0461 - val_loss: 1.1157\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 4.4285 - val_loss: 0.6404\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 4.0367 - val_loss: 0.8594\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 715.6452 - val_loss: 0.9653\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 19.9543 - val_loss: 0.1566\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 15.4448 - val_loss: 0.4812\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 12.3216 - val_loss: 0.0941\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 9.7897 - val_loss: 0.2369\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 7.4803 - val_loss: 0.3188\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 5.5722 - val_loss: 0.2285\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 3.9060 - val_loss: 0.1666\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 2.8176 - val_loss: 0.2231\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 2.1266 - val_loss: 0.6319\n",
            "Final Model MSE: 0.03214782917683093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pygad/pygad.py:724: UserWarning: The percentage of genes to mutate (mutation_percent_genes=10) resulted in selecting (0) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\n",
            "If you do not want to mutate any gene, please set mutation_type=None.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F5mJAo070ARF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Expected features:\", scaler.n_features_in_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pi--3siEMgj",
        "outputId": "11b25edd-7b51-43b3-9624-cb60696343be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected features: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit pyngrok --quiet"
      ],
      "metadata": {
        "id": "yl_-TDcb1TYF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "gYlGhAcI1YFH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import joblib\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# ‚úÖ Set Gemini API Key (Replace with your actual key)\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCYF1gM_i6H9Gt9YuNsG1Vc-PlNRINQfe8\"\n",
        "\n",
        "# ‚úÖ Configure Gemini API\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "# ‚úÖ Load Model & Scaler\n",
        "try:\n",
        "    scaler = joblib.load(\"scaler.pkl\")\n",
        "    xgb_model = joblib.load(\"xgb_model.pkl\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading models: {e}\")\n",
        "\n",
        "# ‚úÖ Define feature names\n",
        "feature_names = [\"Energy Consumption (kWh)\", \"Transport Distance (km)\", \"Waste Generated (kg)\",\n",
        "                 \"Diet Impact Score\", \"Sector Impact Score\", \"Industrial Energy Usage (kWh)\"]\n",
        "\n",
        "# ‚úÖ Streamlit UI Configuration\n",
        "st.set_page_config(page_title=\"üåç Carbon Footprint Tracker & Sustainability Chatbot\", layout=\"centered\")\n",
        "\n",
        "# ‚úÖ **App Title**\n",
        "st.title(\"üåç Carbon Footprint Tracker\")\n",
        "\n",
        "# ‚úÖ **User Instructions**\n",
        "st.markdown(\"\"\"\n",
        "### ‚ÑπÔ∏è **How to Use This App**\n",
        "1. **Enter your details** such as energy usage, transport distance, and waste generation.\n",
        "2. **Understand the scores:**\n",
        "   - **Diet Impact Score** ü•ó: Measures the environmental impact of your diet (0 = low impact, 1 = high impact).\n",
        "   - **Sector Impact Score** üè≠: Reflects emissions based on your industry or business sector.\n",
        "3. Click on **üîç Predict Carbon Footprint** to get your estimated CO2 emissions.\n",
        "4. Explore **üìä SHAP Analysis** to see which factors contribute most to your footprint.\n",
        "5. Use **üöÄ Reduction Strategies** to lower your emissions.\n",
        "6. Chat with **üí¨ Gemini AI** for sustainability tips!\n",
        "\"\"\")\n",
        "\n",
        "# ‚úÖ **User Inputs**\n",
        "st.sidebar.header(\"üå± **Enter Your Details**\")\n",
        "\n",
        "user_type = st.sidebar.selectbox(\"Select User Type\", [\"Individual\", \"Business\"])\n",
        "energy_usage = st.sidebar.number_input(\"‚ö° Energy Consumption (kWh)\", min_value=0.0)\n",
        "transport_distance = st.sidebar.number_input(\"üöó Transport Distance (km)\", min_value=0.0)\n",
        "waste_generated = st.sidebar.number_input(\"‚ôªÔ∏è Waste Generated (kg)\", min_value=0.0)\n",
        "diet_impact = st.sidebar.slider(\"ü•ó Diet Impact Score (0 = Low, 1 = High)\", min_value=0.0, max_value=1.0, step=0.1)\n",
        "sector_impact = st.sidebar.slider(\"üè≠ Sector Impact Score (0 = Low, 1 = High)\", min_value=0.0, max_value=1.0, step=0.1)\n",
        "industrial_usage = st.sidebar.number_input(\"‚öôÔ∏è Industrial Energy Usage (kWh)\", min_value=0.0)\n",
        "\n",
        "# ‚úÖ **Carbon Footprint Prediction**\n",
        "if st.sidebar.button(\"üîç Predict Carbon Footprint\"):\n",
        "    try:\n",
        "        # Prepare input data\n",
        "        user_input = np.array([[energy_usage, transport_distance, waste_generated, diet_impact, sector_impact, industrial_usage]])\n",
        "        user_input_scaled = scaler.transform(user_input)\n",
        "\n",
        "        # Convert to DataFrame for SHAP compatibility\n",
        "        user_input_df = pd.DataFrame(user_input_scaled, columns=feature_names)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = xgb_model.predict(user_input_scaled)\n",
        "        st.subheader(f\"üå± **Estimated Carbon Footprint: {prediction[0]:.2f} tons CO2/year**\")\n",
        "\n",
        "        # Generate SHAP Explainer\n",
        "        X_train_sample = pd.DataFrame(np.random.randn(10, len(feature_names)), columns=feature_names)\n",
        "        explainer = shap.Explainer(xgb_model, X_train_sample)\n",
        "        shap_values = explainer(user_input_df)\n",
        "\n",
        "        # ‚úÖ **SHAP Waterfall Plot**\n",
        "        st.subheader(\"üìä SHAP Waterfall Plot - Feature Contribution\")\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        shap.waterfall_plot(shap_values[0], show=False)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # ‚úÖ **SHAP Beeswarm Plot**\n",
        "        st.subheader(\"üìä SHAP Beeswarm Plot - Feature Importance\")\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        shap.summary_plot(shap_values, user_input_df, feature_names=feature_names, show=False)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # ‚úÖ **Personalized Reduction Strategies**\n",
        "        st.subheader(\"üöÄ Reduction Strategies\")\n",
        "        strategies = []\n",
        "\n",
        "        if energy_usage > 300:\n",
        "            strategies.append(\"üîã Reduce energy consumption by switching to renewable sources like solar or wind.\")\n",
        "        if transport_distance > 200:\n",
        "            strategies.append(\"üö≤ Use public transport, carpool, or switch to electric vehicles.\")\n",
        "        if waste_generated > 50:\n",
        "            strategies.append(\"‚ôªÔ∏è Reduce waste by recycling, composting, and minimizing single-use plastics.\")\n",
        "        if diet_impact > 0.6:\n",
        "            strategies.append(\"ü•ó Consider a plant-based diet or reducing meat consumption to lower emissions.\")\n",
        "        if industrial_usage > 1000:\n",
        "            strategies.append(\"üè≠ Optimize industrial energy use with smart grid technology and energy-efficient machinery.\")\n",
        "\n",
        "        if strategies:\n",
        "            for strategy in strategies:\n",
        "                st.write(strategy)\n",
        "        else:\n",
        "            st.write(\"‚úÖ Your carbon footprint is already low! Keep up the sustainable practices. üéâ\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during prediction: {e}\")\n",
        "\n",
        "# ‚úÖ **Chatbot Section with Session State Fix**\n",
        "with st.expander(\"üí¨ **Ask Gemini AI About Sustainability**\"):\n",
        "    st.write(\"Ask anything related to sustainability, climate change, and carbon footprint reduction.\")\n",
        "\n",
        "    # ‚úÖ Initialize chat history in session state\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    user_query = st.text_input(\"Type your question:\")\n",
        "\n",
        "    if st.button(\"Ask Gemini\"):\n",
        "        if user_query:\n",
        "            def gemini_chatbot(question):\n",
        "                try:\n",
        "                    model = genai.GenerativeModel(\"gemini-pro\")\n",
        "                    response = model.generate_content(question)\n",
        "                    return response.text if hasattr(response, \"text\") else \"Sorry, I couldn't generate a response.\"\n",
        "                except Exception as e:\n",
        "                    return f\"Error: {e}\"\n",
        "\n",
        "            # ‚úÖ Get AI response\n",
        "            response = gemini_chatbot(user_query)\n",
        "\n",
        "            # ‚úÖ Store conversation in session state\n",
        "            st.session_state.chat_history.append((\"You: \" + user_query, \"ü§ñ Gemini AI: \" + response))\n",
        "\n",
        "    # ‚úÖ Display chat history\n",
        "    for user_msg, ai_msg in st.session_state.chat_history:\n",
        "        st.write(user_msg)\n",
        "        st.write(ai_msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQjd8v071kVx",
        "outputId": "612bdf22-f03e-4554-db3b-2cdb051bc4b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import joblib\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# ‚úÖ Set Gemini API Key (Replace with your actual key)\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCYF1gM_i6H9Gt9YuNsG1Vc-PlNRINQfe8\"\n",
        "\n",
        "# ‚úÖ Configure Gemini API\n",
        "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "# ‚úÖ Load Model & Scaler\n",
        "try:\n",
        "    scaler = joblib.load(\"scaler.pkl\")\n",
        "    xgb_model = joblib.load(\"xgb_model.pkl\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading models: {e}\")\n",
        "\n",
        "# ‚úÖ Define feature names\n",
        "feature_names = [\"Energy Consumption (kWh)\", \"Transport Distance (km)\", \"Waste Generated (kg)\",\n",
        "                 \"Diet Impact Score\", \"Sector Impact Score\", \"Industrial Energy Usage (kWh)\"]\n",
        "\n",
        "# ‚úÖ Streamlit UI\n",
        "st.set_page_config(page_title=\"üåç Carbon Footprint Tracker & Sustainability Chatbot\", layout=\"centered\")\n",
        "\n",
        "st.title(\"üåç Carbon Footprint Tracker\")\n",
        "\n",
        "user_type = st.selectbox(\"Select User Type\", [\"Individual\", \"Business\"])\n",
        "energy_usage = st.number_input(\"‚ö° Energy Consumption (kWh)\", min_value=0.0)\n",
        "transport_distance = st.number_input(\"üöó Transport Distance (km)\", min_value=0.0)\n",
        "waste_generated = st.number_input(\"‚ôªÔ∏è Waste Generated (kg)\", min_value=0.0)\n",
        "diet_impact = st.number_input(\"ü•ó Diet Impact Score\", min_value=0.0)\n",
        "sector_impact = st.number_input(\"üè≠ Sector Impact Score\", min_value=0.0)\n",
        "industrial_usage = st.number_input(\"‚öôÔ∏è Industrial Energy Usage (kWh)\", min_value=0.0)\n",
        "\n",
        "if st.button(\"üîç Predict Carbon Footprint\"):\n",
        "    try:\n",
        "        # Prepare input data\n",
        "        user_input = np.array([[energy_usage, transport_distance, waste_generated, diet_impact, sector_impact, industrial_usage]])\n",
        "        user_input_scaled = scaler.transform(user_input)\n",
        "\n",
        "        # Convert to DataFrame for SHAP compatibility\n",
        "        user_input_df = pd.DataFrame(user_input_scaled, columns=feature_names)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = xgb_model.predict(user_input_scaled)\n",
        "        st.write(f\"üå± **Estimated Carbon Footprint: {prediction[0]:.2f} tons CO2/year**\")\n",
        "\n",
        "        # Generate SHAP Explainer\n",
        "        X_train_sample = pd.DataFrame(np.random.randn(10, len(feature_names)), columns=feature_names)\n",
        "        explainer = shap.Explainer(xgb_model, X_train_sample)\n",
        "        shap_values = explainer(user_input_df)\n",
        "\n",
        "        # SHAP Waterfall Plot\n",
        "        st.subheader(\"üìä SHAP Waterfall Plot - Feature Contribution\")\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        shap.waterfall_plot(shap_values[0], show=False)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # SHAP Beeswarm Plot\n",
        "        st.subheader(\"üìä SHAP Beeswarm Plot - Feature Importance\")\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        shap.summary_plot(shap_values, user_input_df, feature_names=feature_names, show=False)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Provide Personalized Reduction Strategies\n",
        "        st.subheader(\"üöÄ Reduction Strategies\")\n",
        "        strategies = []\n",
        "\n",
        "        if energy_usage > 300:\n",
        "            strategies.append(\"üîã Reduce energy consumption by switching to renewable sources like solar or wind.\")\n",
        "        if transport_distance > 200:\n",
        "            strategies.append(\"üö≤ Use public transport, carpool, or switch to electric vehicles.\")\n",
        "        if waste_generated > 50:\n",
        "            strategies.append(\"‚ôªÔ∏è Reduce waste by recycling, composting, and minimizing single-use plastics.\")\n",
        "        if diet_impact > 0.6:\n",
        "            strategies.append(\"ü•ó Consider a plant-based diet or reducing meat consumption to lower emissions.\")\n",
        "        if industrial_usage > 1000:\n",
        "            strategies.append(\"üè≠ Optimize industrial energy use with smart grid technology and energy-efficient machinery.\")\n",
        "\n",
        "        if strategies:\n",
        "            for strategy in strategies:\n",
        "                st.write(strategy)\n",
        "        else:\n",
        "            st.write(\"‚úÖ Your carbon footprint is already low! Keep up the sustainable practices. üéâ\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during prediction: {e}\")\n",
        "\n",
        "# ‚úÖ Chatbot Section with Session State Fix\n",
        "with st.expander(\"üí¨ **Ask Gemini AI About Sustainability**\"):\n",
        "    st.write(\"Ask anything related to sustainability, climate change, and carbon footprint reduction.\")\n",
        "\n",
        "    # ‚úÖ Initialize chat history in session state\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    user_query = st.text_input(\"Type your question:\")\n",
        "\n",
        "    if st.button(\"Ask Gemini\"):\n",
        "        if user_query:\n",
        "            def gemini_chatbot(question):\n",
        "                try:\n",
        "                    model = genai.GenerativeModel(\"gemini-pro\")\n",
        "                    response = model.generate_content(question)\n",
        "                    return response.text if hasattr(response, \"text\") else \"Sorry, I couldn't generate a response.\"\n",
        "                except Exception as e:\n",
        "                    return f\"Error: {e}\"\n",
        "\n",
        "            # ‚úÖ Get AI response\n",
        "            response = gemini_chatbot(user_query)\n",
        "\n",
        "            # ‚úÖ Store conversation in session state\n",
        "            st.session_state.chat_history.append((\"You: \" + user_query, \"ü§ñ Gemini AI: \" + response))\n",
        "\n",
        "    # ‚úÖ Display chat history\n",
        "    for user_msg, ai_msg in st.session_state.chat_history:\n",
        "        st.write(user_msg)\n",
        "        st.write(ai_msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b727ac-fb80-4500-87d2-b061b0eec53a",
        "id": "vzbFXmcPzDY1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmHHPiv91hq8",
        "outputId": "fc5484e9-b6f9-46c4-e22e-4af9c20554b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgb_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGUewsU5EQXN",
        "outputId": "561385cd-def0-4ca1-c818-2c6b67bd8325"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.231.7:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0Kyour url is: https://five-chairs-begin.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740283004.546871   12165 init.cc:232] grpc_wait_for_shutdown_with_timeout() timed out.\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}